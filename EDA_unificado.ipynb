{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA Unificado (Practica 4)\n",
        "\n",
        "Objetivo: limpiar y estandarizar variables clave, documentar el tratamiento de nulos/outliers y dejar una base consistente para modelado posterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "pd.set_option('display.max_columns', 200)\n",
        "pd.set_option('display.max_rows', 120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 1) Carga de datos (prioriza data/listings.csv.gz) ===\n",
        "DATA_CANDIDATES = [\n",
        "    Path('data/listings.csv.gz'),\n",
        "    Path('listings.csv.gz'),\n",
        "    Path('listings.csv'),\n",
        "]\n",
        "\n",
        "data_path = None\n",
        "for p in DATA_CANDIDATES:\n",
        "    if p.exists():\n",
        "        data_path = p\n",
        "        break\n",
        "\n",
        "if data_path is None:\n",
        "    raise FileNotFoundError('No se encontro listings.csv.gz ni listings.csv')\n",
        "\n",
        "compression = 'gzip' if data_path.suffix == '.gz' else None\n",
        "df = pd.read_csv(data_path, compression=compression, low_memory=False)\n",
        "\n",
        "print('Data path:', data_path)\n",
        "print('Shape:', df.shape)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 2) Resumen rapido ===\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 3) Nulos y cardinalidad (idea de practica4_dmc) ===\n",
        "\n",
        "def detect_drop_candidates(df, missing_threshold=60, high_card_threshold=200, long_text_len=80):\n",
        "    rows = []\n",
        "    n = len(df)\n",
        "    for col in df.columns:\n",
        "        s = df[col]\n",
        "        n_missing = s.isna().sum()\n",
        "        pct_missing = (n_missing / n) * 100\n",
        "        n_unique = s.nunique(dropna=True)\n",
        "        sample = s.dropna().astype(str).head(3).tolist()\n",
        "        mean_len = None\n",
        "        if s.dtype == 'object':\n",
        "            mean_len = s.dropna().astype(str).str.len().mean()\n",
        "        reasons = []\n",
        "        if pct_missing > missing_threshold:\n",
        "            reasons.append(f'missing>{missing_threshold}%')\n",
        "        if n_unique > high_card_threshold:\n",
        "            reasons.append('high_card')\n",
        "        if s.dtype == 'object' and mean_len and mean_len > long_text_len:\n",
        "            reasons.append('long_text')\n",
        "        if s.dtype == 'object' and s.astype(str).str.contains('http', case=False, na=False).mean() > 0.2:\n",
        "            reasons.append('url_like')\n",
        "        rows.append({\n",
        "            'col': col,\n",
        "            'pct_missing': round(pct_missing, 2),\n",
        "            'n_unique': n_unique,\n",
        "            'mean_len': None if mean_len is None else round(mean_len, 1),\n",
        "            'sample': sample,\n",
        "            'reasons': ', '.join(reasons)\n",
        "        })\n",
        "    return pd.DataFrame(rows).sort_values(by=['pct_missing','n_unique'], ascending=False)\n",
        "\n",
        "missing_report = detect_drop_candidates(df)\n",
        "missing_report.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 4) Price clean + log (dmc + main + jimena) ===\n",
        "if 'price' in df.columns:\n",
        "    df['price_clean'] = (\n",
        "        df['price'].astype(str)\n",
        "        .str.replace(r'[,$]', '', regex=True)\n",
        "    )\n",
        "    df['price_clean'] = pd.to_numeric(df['price_clean'], errors='coerce')\n",
        "    df['log_price_clean'] = np.log1p(df['price_clean'])\n",
        "\n",
        "df[['price', 'price_clean', 'log_price_clean']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 5) Normalizacion de rates (jjvv) ===\n",
        "for col in ['host_response_rate', 'host_acceptance_rate']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(str).str.replace('%', '', regex=False)\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "df[['host_response_rate','host_acceptance_rate']].describe() if 'host_response_rate' in df.columns else 'rates not found'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 6) Amenities: lista, conteo, grupos, y amenities clave ===\n",
        "\n",
        "def parse_amenities(text):\n",
        "    if pd.isna(text):\n",
        "        return []\n",
        "    text = str(text).strip('{}')\n",
        "    parts = [p.strip().strip('\"').strip(\"'\") for p in text.split(',')]\n",
        "    return [p for p in parts if p]\n",
        "\n",
        "if 'amenities' in df.columns:\n",
        "    df['amenities_list'] = df['amenities'].apply(parse_amenities)\n",
        "    df['amenities_count'] = df['amenities_list'].apply(len)\n",
        "\n",
        "    # Amenidades clave (main)\n",
        "    key_amenities = ['Wifi', 'Air conditioning', 'Pool', 'Kitchen', 'Parking']\n",
        "    for amenity in key_amenities:\n",
        "        col = f\"has_{amenity.lower().replace(' ', '_')}\"\n",
        "        df[col] = df['amenities_list'].apply(\n",
        "            lambda lst: int(any(amenity.lower() in a.lower() for a in lst))\n",
        "        )\n",
        "\n",
        "    # Amenidades por grupo (jimena)\n",
        "    amenity_groups = {\n",
        "        'comfort': ['air conditioning', 'heating', 'washer', 'dryer', 'tv'],\n",
        "        'kitchen': ['kitchen', 'microwave', 'refrigerator', 'oven', 'coffee'],\n",
        "        'laundry': ['washer', 'dryer', 'iron'],\n",
        "        'leisure': ['pool', 'gym', 'hot tub', 'balcony', 'patio'],\n",
        "        'business': ['wifi', 'workspace', 'desk'],\n",
        "        'parking': ['parking', 'garage']\n",
        "    }\n",
        "    for group, kws in amenity_groups.items():\n",
        "        col = f'amenities_{group}'\n",
        "        df[col] = df['amenities_list'].apply(\n",
        "            lambda lst: int(any(any(kw in a.lower() for kw in kws) for a in lst))\n",
        "        )\n",
        "\n",
        "df[['amenities_count']].describe() if 'amenities_count' in df.columns else 'amenities not found'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 7) Features de capacidad / layout (dmc + zg) ===\n",
        "for col in ['accommodates','bedrooms','beds']:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "df['total_capacity'] = df['accommodates'].fillna(0) + df['bedrooms'].fillna(0) + df['beds'].fillna(0)\n",
        "df['bed_per_person'] = df['beds'] / df['accommodates'].replace(0, np.nan)\n",
        "df['bedroom_per_person'] = df['bedrooms'] / df['accommodates'].replace(0, np.nan)\n",
        "df['space_per_person'] = df['total_capacity'] / df['accommodates'].replace(0, np.nan)\n",
        "\n",
        "df[['total_capacity','bed_per_person','bedroom_per_person','space_per_person']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 8) Geografia: distancias (dmc + jjvv) ===\n",
        "\n",
        "def haversine(lat, lon, lat0, lon0):\n",
        "    R = 6371.0\n",
        "    lat1 = np.radians(lat)\n",
        "    lon1 = np.radians(lon)\n",
        "    lat2 = np.radians(lat0)\n",
        "    lon2 = np.radians(lon0)\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "    return R * c\n",
        "\n",
        "if 'latitude' in df.columns and 'longitude' in df.columns:\n",
        "    # Centro CDMX (Zocalo)\n",
        "    ZOCALO = (19.4326, -99.1332)\n",
        "    AICM = (19.4361, -99.0719)\n",
        "    df['dist_zocalo_km'] = haversine(df['latitude'], df['longitude'], *ZOCALO)\n",
        "    df['dist_aicm_km'] = haversine(df['latitude'], df['longitude'], *AICM)\n",
        "    df['distance_from_center_km'] = df['dist_zocalo_km']\n",
        "    df['is_central_location'] = (df['distance_from_center_km'] < 5).astype(int)\n",
        "\n",
        "df[['dist_zocalo_km','dist_aicm_km','distance_from_center_km']].describe() if 'dist_zocalo_km' in df.columns else 'geo not found'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 9) Temporalidad y recencia (jimena) ===\n",
        "for col in ['last_scraped','last_review','first_review','host_since']:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "\n",
        "if 'last_scraped' in df.columns and 'last_review' in df.columns:\n",
        "    df['days_since_last_review'] = (df['last_scraped'] - df['last_review']).dt.days\n",
        "\n",
        "if 'last_scraped' in df.columns and 'host_since' in df.columns:\n",
        "    df['host_tenure_days'] = (df['last_scraped'] - df['host_since']).dt.days\n",
        "\n",
        "# Recency groups\n",
        "if 'days_since_last_review' in df.columns:\n",
        "    bins = [-1, 30, 90, 180, 365, 99999]\n",
        "    labels = ['<=30', '31-90', '91-180', '181-365', '>365']\n",
        "    df['recency_group'] = pd.cut(df['days_since_last_review'], bins=bins, labels=labels)\n",
        "\n",
        "df[['days_since_last_review','host_tenure_days']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 10) Disponibilidad / actividad (dmc + zg) ===\n",
        "if 'availability_365' in df.columns:\n",
        "    df['availability_rate'] = df['availability_365'] / 365\n",
        "    df['scarcity_score'] = 1 - df['availability_rate']\n",
        "\n",
        "if 'maximum_nights' in df.columns and 'minimum_nights' in df.columns:\n",
        "    df['booking_flexibility'] = df['maximum_nights'] - df['minimum_nights']\n",
        "\n",
        "df[['availability_rate','scarcity_score','booking_flexibility']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 11) NLP simple para lujo (equipo_5) ===\n",
        "# No requiere nltk. Es un conteo simple de palabras clave en descripcion.\n",
        "luxury_keywords = [\n",
        "    'luxury','lujo','premium','exclusivo','exclusive','elegante','elegant',\n",
        "    'boutique','vista','panoramica','private','privado','spacious','amplio'\n",
        "]\n",
        "\n",
        "if 'description' in df.columns:\n",
        "    desc = df['description'].fillna('').str.lower()\n",
        "    df['luxury_keyword_count'] = desc.apply(\n",
        "        lambda x: sum(1 for kw in luxury_keywords if kw in x)\n",
        "    )\n",
        "    df['is_luxury_property'] = (df['luxury_keyword_count'] > 0).astype(int)\n",
        "\n",
        "df[['luxury_keyword_count','is_luxury_property']].describe() if 'description' in df.columns else 'description not found'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 12) Outliers (IQR / winsor / clip) ===\n",
        "if 'price_clean' in df.columns:\n",
        "    # Clip suave 1%-99%\n",
        "    q01, q99 = df['price_clean'].quantile([0.01, 0.99])\n",
        "    df['price_clean_clip'] = df['price_clean'].clip(q01, q99)\n",
        "\n",
        "    # IQR\n",
        "    q1 = df['price_clean'].quantile(0.25)\n",
        "    q3 = df['price_clean'].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower = q1 - 1.5 * iqr\n",
        "    upper = q3 + 1.5 * iqr\n",
        "    df['price_clean_iqr'] = df['price_clean'].clip(lower, upper)\n",
        "\n",
        "df[['price_clean','price_clean_clip','price_clean_iqr']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 13) Leakage candidates (main) ===\n",
        "LEAKAGE_KEYWORDS = [\n",
        "    'price', 'review', 'revenue', 'availability', 'occupancy', 'estimated',\n",
        "    'calculated_host_listings_count'\n",
        "]\n",
        "leakage_cols = [c for c in df.columns if any(k in c.lower() for k in LEAKAGE_KEYWORDS)]\n",
        "leakage_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 14) Correlaciones Spearman con price_clean (dmc) ===\n",
        "if 'price_clean' in df.columns:\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    num_cols = [c for c in num_cols if c != 'price_clean']\n",
        "    corr = df[num_cols].corrwith(df['price_clean'], method='spearman').sort_values(ascending=False)\n",
        "    corr.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Siguientes pasos\n",
        "- Definir el target final (price_clean vs log_price_clean).\n",
        "- Seleccionar features base (y excluir leakage).\n",
        "- Crear pipeline de preprocesamiento y baseline de modelos."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
